{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考文档：[Azure OpenAI 入门教程 - LangChain 篇 ：Memory 存储](https://zhuanlan.zhihu.com/p/643241551)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 你好，我是Alex\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好Alex！我是AI助手，很高兴认识你。有什么我可以帮助你的吗？'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "conversation.predict(input = \"你好，我是Alex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你好，我是Alex\n",
      "AI: 你好Alex！我是AI助手，很高兴认识你。有什么我可以帮助你的吗？\n",
      "Human: 请问1+1等于几\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1等于2。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"请问1+1等于几\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你好，我是Alex\n",
      "AI: 你好Alex！我是AI助手，很高兴认识你。有什么我可以帮助你的吗？\n",
      "Human: 请问1+1等于几\n",
      "AI: 1+1等于2。\n",
      "Human: 我叫什么名字？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你叫Alex。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"我叫什么名字？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好，我是Alex\n",
      "AI: 你好Alex！我是AI助手，很高兴认识你。有什么我可以帮助你的吗？\n",
      "Human: 请问1+1等于几\n",
      "AI: 1+1等于2。\n",
      "Human: 我叫什么名字？\n",
      "AI: 你叫Alex。\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我是Alex\\nAI: 你好Alex！我是AI助手，很高兴认识你。有什么我可以帮助你的吗？\\nHuman: 请问1+1等于几\\nAI: 1+1等于2。\\nHuman: 我叫什么名字？\\nAI: 你叫Alex。'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好\n",
      "AI: 你好怎么了\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "memory.save_context({\"input\": \"你好\"},\n",
    "                    {\"output\": \"你好怎么了\"})\n",
    "\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好\\nAI: 你好怎么了\\nHuman: 还不错\\nAI: 太好了'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context({\"input\": \"还不错\"},\n",
    "                    {\"output\": \"太好了\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 还不错\\nAI: 太好了'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k = 1)\n",
    "\n",
    "memory.save_context({\"input\": \"你好\"},\n",
    "                    {\"output\": \"你好，怎么了\"})\n",
    "memory.save_context({\"input\": \"还不错\"},\n",
    "                    {\"output\": \"太好了\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，Alex！很高兴认识你。我是一个AI助手，我可以回答你的问题和提供信息。有什么我可以帮助你的吗？'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k = 1)\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = False\n",
    ")\n",
    "\n",
    "conversation.predict(input = \"你好，我叫Alex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1等于2。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"1+1等于多少\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'很抱歉，我不知道您的名字是什么。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"我的名字是什么？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 我叫什么？\\nAI: XXX'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "memory = ConversationTokenBufferMemory(llm = llm, max_token_limit = 30)\n",
    "memory.save_context({\"input\": \"你好，我叫XXX\"},\n",
    "                    {\"output\": \"你好\"})\n",
    "memory.save_context({\"input\": \"1+1等于几？\"},\n",
    "                    {\"output\": \"1+1等于2！\"})\n",
    "memory.save_context({\"input\": \"我叫什么？\"},\n",
    "                    {\"output\": \"XXX\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI in Chinese and asks about their schedule for the day. The AI responds and provides a detailed schedule including a meeting with the product team, working on the LangChain project, and having lunch with a client to discuss the latest AI technology. The AI also reminds the human to bring their laptop to show the latest LLM presentation.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# create a long string\n",
    "schedule = \"早上8点有与你的产品团队的会议，\\\n",
    "需要准备好你的PowerPoint演示文稿。\\\n",
    "上午9点至中午12点有时间来处理LangChain项目，因为LangChain是如果强大的工具，所以进展会很快。\\\n",
    "中午，在意大利餐厅和一位客户共进午餐，他将从一个多小时之外驱车前来与您网页，了解最新的人工智能技术。\\\n",
    "记得带上笔记本电脑显示最新的LLM演示。\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm = llm, max_token_limit = 100)\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"你好，怎么了\"})\n",
    "memory.save_context({\"input\": \"没啥，打声招呼\"}, {\"output\": \"好吧\"})\n",
    "memory.save_context({\"input\": \"今天的计划日程是怎么安排的？\"}, {\"output\": f\"{schedule}\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI in Chinese and asks about their schedule for the day. The AI responds and provides a detailed schedule including a meeting with the product team, working on the LangChain project, and having lunch with a client to discuss the latest AI technology. The AI also reminds the human to bring their laptop to show the latest LLM presentation.\n",
      "Human: 有什么 demo 可以演示？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI in Chinese and asks about their schedule for the day. The AI responds with a detailed schedule, including a meeting with the product team, working on the LangChain project, and having lunch with a client to discuss the latest AI technology. The AI also reminds the human to bring their laptop to show the latest LLM presentation. The human asks if there are any demos available to showcase.\\nAI: 我们可以展示LangChain项目的最新功能，包括自动翻译和语音识别。另外，我们还可以演示最新的AI技术在图像识别和人脸识别方面的应用。您有什么特别的要求吗？'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(llm = llm, memory = memory, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"有什么 demo 可以演示？\")\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
