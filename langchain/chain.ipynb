{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考文档：[Azure OpenAI 入门教程 - LangChain 篇 ：Chain 链的基本概念](https://zhuanlan.zhihu.com/p/643463558)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 你好，我是Alex\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好，Alex！很高兴认识你。我是一款人工智能助手，可以回答各种问题和提供帮助。有什么我可以帮你的吗？'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"你好，我是Alex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'儿童牙刷公司的名字可以是：\\n1. \"儿童牙乐乐\"\\n2. \"小小白牙刷\"\\n3. \"童趣牙膏\"\\n4. \"宝宝牙刷坊\"\\n5. \"乐乐牙刷\"\\n6. \"儿童牙宝\"\\n7. \"小牙精\"\\n8. \"童趣口腔护理\"\\n9. \"宝宝口腔健康\"\\n10. \"儿童牙齿天使\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"为产品是 {product} 的公司起一个名字\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "product = \"儿童牙刷\"\n",
    "chain.run(product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m1. 小小清耳\n",
      "2. 爱耳宝\n",
      "3. 耳朵小帮手\n",
      "4. 童趣挖耳\n",
      "5. 星耳宝\n",
      "6. 快乐挖耳\n",
      "7. 耳朵小调查员\n",
      "8. 耳朵小助手\n",
      "9. 挖耳探险队\n",
      "10. 耳朵小守护者\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m公司名：星耳宝\n",
      "\n",
      "星耳宝是一家专注于耳朵健康的公司。我们的使命是为用户提供高质量、安全可靠的耳朵护理产品和服务，帮助人们保持健康的听觉和舒适的耳朵。\n",
      "\n",
      "作为耳朵小守护者，我们致力于研发和生产创新的耳朵护理产品，以满足不同用户的需求。我们的产品包括小型清耳器具、耳朵小帮手等，这些产品具有便携、易用、安全的特点，可以有效清理耳垢、缓解耳朵不适，提供舒适的耳朵护理体验。\n",
      "\n",
      "除了产品，我们还提供专业的耳朵护理指导和服务。我们拥有一支经验丰富的耳朵小调查员团队，为用户提供定制化的耳朵护理方案，并解答用户在耳朵健康方面的疑问。我们的目标是通过科学的、个性化的耳朵护理，帮助用户预防耳朵疾病，提升听力质量，提高生活质量。\n",
      "\n",
      "作为一家有社会责任感的企业，星耳宝注重环保和可持续发展。我们致力于减少对环境的负面影响，并积极参与公益事业，推动耳朵健康意识的普及。\n",
      "\n",
      "我们相信，通过星耳宝的产品和服务，每个人都可以拥有健康、舒适的耳朵，享受美好的听觉体验。加入我们，成为耳朵健康的倡导者和实践者！\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'公司名：星耳宝\\n\\n星耳宝是一家专注于耳朵健康的公司。我们的使命是为用户提供高质量、安全可靠的耳朵护理产品和服务，帮助人们保持健康的听觉和舒适的耳朵。\\n\\n作为耳朵小守护者，我们致力于研发和生产创新的耳朵护理产品，以满足不同用户的需求。我们的产品包括小型清耳器具、耳朵小帮手等，这些产品具有便携、易用、安全的特点，可以有效清理耳垢、缓解耳朵不适，提供舒适的耳朵护理体验。\\n\\n除了产品，我们还提供专业的耳朵护理指导和服务。我们拥有一支经验丰富的耳朵小调查员团队，为用户提供定制化的耳朵护理方案，并解答用户在耳朵健康方面的疑问。我们的目标是通过科学的、个性化的耳朵护理，帮助用户预防耳朵疾病，提升听力质量，提高生活质量。\\n\\n作为一家有社会责任感的企业，星耳宝注重环保和可持续发展。我们致力于减少对环境的负面影响，并积极参与公益事业，推动耳朵健康意识的普及。\\n\\n我们相信，通过星耳宝的产品和服务，每个人都可以拥有健康、舒适的耳朵，享受美好的听觉体验。加入我们，成为耳朵健康的倡导者和实践者！'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\"为产品是 {product} 的公司起一个名字\") \n",
    "\n",
    "# chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "\n",
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\"为公司写一段介绍，公司名：{company_name}\")\n",
    "\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)\n",
    "\n",
    "product = \"儿童挖耳勺\"\n",
    "\n",
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: HTTP code 500 from API ().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': '我最近购买了一款儿童挖耳勺，使用后感觉非常不错。首先，这款挖耳勺的设计非常人性化，有着舒适的手柄和适宜儿童使用的小尺寸，让孩子容易掌握并使用。其次，挖耳勺的材质非常安全，采用了医用级别的不锈钢材质，不易生锈，也不会对孩子的耳道造成伤害。最重要的是，使用后能够有效清洁耳朵，让孩子的耳朵保持清洁和健康。总之，这款儿童挖耳勺是一款非常实用和安全的产品，我非常满意并强烈推荐。',\n",
       " 'English_Review': \"I recently purchased a children's ear spoon, and I feel it is very good to use. Firstly, the design of this ear spoon is very user-friendly, with a comfortable handle and a small size suitable for children, making it easy for children to grasp and use. Secondly, the material of the ear spoon is very safe, using medical-grade stainless steel, which is not easy to rust and will not harm the child's ear canal. Most importantly, it effectively cleans the ears, keeping the child's ears clean and healthy. In conclusion, this children's ear spoon is a very practical and safe product, and I am very satisfied and highly recommend it.\",\n",
       " 'summary': \"The commenter highly recommends a children's ear spoon due to its user-friendly design, safe materials, and effective ear cleaning capabilities, making it a practical and satisfactory product for keeping children's ears clean and healthy.\",\n",
       " 'followup_message': '跟进回复：非常感谢您对我们儿童耳勺的高度推荐！我们的儿童耳勺设计用户友好，采用安全材料，并具有有效的耳部清洁功能，可以帮助孩子保持耳朵的清洁和健康。我们非常重视您的反馈，您的支持对我们来说非常重要！'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# prompt template 1: translate to English\n",
    "first_prompt = ChatPromptTemplate.from_template(\"将下面的评论翻译成英文：\"\n",
    "                                                \"\\n\\n{Review}\")\n",
    "# chain 1: input = Review and output = English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key=\"English_Review\")\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\"你能用一句话概括一下评论吗？\\n\\n{English_Review}\")\n",
    "# chain 2: input = English_Review and output = summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key=\"summary\")\n",
    "\n",
    "# prompt template 3: translate to English\n",
    "third_prompt = ChatPromptTemplate.from_template(\"下面的评论内容使用的是哪种语言：\\n\\n{Review}\")\n",
    "# chain 3: input = Review and output = language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")\n",
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\"把下面的摘要翻译成指定语言，并写一份跟进回复。\"\n",
    "                                                 \"\\n\\n摘要：{summary}\\n\\n语言：{language}\")\n",
    "#c chain 4: input = summary, language and output = followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"followup_message\")\n",
    "\n",
    "# overall_chain: input = Review\n",
    "# and output = English_Review, summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"Review\"],\n",
    "    output_variables=[\"English_Review\", \"summary\", \"followup_message\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "review = \"我最近购买了一款儿童挖耳勺，\\\n",
    "使用后感觉非常不错。首先，这款挖耳勺的设计非常人性化，\\\n",
    "有着舒适的手柄和适宜儿童使用的小尺寸，让孩子容易掌握并使用。\\\n",
    "其次，挖耳勺的材质非常安全，采用了医用级别的不锈钢材质，\\\n",
    "不易生锈，也不会对孩子的耳道造成伤害。\\\n",
    "最重要的是，使用后能够有效清洁耳朵，\\\n",
    "让孩子的耳朵保持清洁和健康。总之，这款儿童挖耳勺是一款非常实用和安全的产品，\\\n",
    "我非常满意并强烈推荐。\"\n",
    "\n",
    "overall_chain(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'physics': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='你是一位非常聪明的物理教授。你擅长以简洁易懂的方式回答有关物理方面的问题。当你不知道某个问题的答案时，你会坦率承认自己不知道。这是我的问题：\\n{input}'))]), llm=ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, openai_api_key='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', openai_api_base='https://proxy-231025.tyler.lu/v1', openai_organization='', openai_proxy='')), 'math': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='你是一个非常优秀的数学家。你擅长回答数学问题。你之所以如此出色，是因为能够将难题拆解成简单部分，回答这些简单部分，然后将它们组合起来就能解决难题。\\n\\n这是我的问题：\\n{input}'))]), llm=ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, openai_api_key='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', openai_api_base='https://proxy-231025.tyler.lu/v1', openai_organization='', openai_proxy='')), 'history': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='你是一位非常优秀的历史学家。你对于各个历史时期的人物、事件和背景有着卓越的知识和理解能力。你具备思考、反思、辩论、讨论和评估历史的能力。你尊重历史证据，并且有能力利用它来支持自己的解释和判断。\\n\\n这是我的问题：{input}'))]), llm=ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, openai_api_key='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', openai_api_base='https://proxy-231025.tyler.lu/v1', openai_organization='', openai_proxy='')), 'computer science': LLMChain(prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='你是一位成功的计算机科学家。你有创造力、懂协作、有前瞻性、有技术问题解决能力、你有对理论和算法的更以及出色的沟通技巧你充满热情。你擅长回答编码问题，因为你知道如何通过描述可由机器轻松解释的命令步骤来解决问题并提供一个在各方面较为平衡的方案。\\n\\n这是我的问题：\\n{input}'))]), llm=ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, openai_api_key='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', openai_api_base='https://proxy-231025.tyler.lu/v1', openai_organization='', openai_proxy=''))}\n",
      "physics: 适合回答物理问题\n",
      "math: 适合回答数学问题\n",
      "history: 适合回答历史问题\n",
      "computer science: 适合回答计算机科学问题\n"
     ]
    }
   ],
   "source": [
    "physics_template = \"\"\"你是一位非常聪明的物理教授。\\\n",
    "你擅长以简洁易懂的方式回答有关物理方面的问题。\\\n",
    "当你不知道某个问题的答案时，你会坦率承认自己不知道。\\\n",
    "这是我的问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "math_template = \"\"\"你是一个非常优秀的数学家。\\\n",
    "你擅长回答数学问题。\\\n",
    "你之所以如此出色，是因为能够将难题拆解成简单部分，\\\n",
    "回答这些简单部分，然后将它们组合起来就能解决难题。\n",
    "\n",
    "这是我的问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"你是一位非常优秀的历史学家。\\\n",
    "你对于各个历史时期的人物、事件和背景有着卓越的知识和理解能力。\\\n",
    "你具备思考、反思、辩论、讨论和评估历史的能力。\\\n",
    "你尊重历史证据，并且有能力利用它来支持自己的解释和判断。\n",
    "\n",
    "这是我的问题：{input}\"\"\"\n",
    "\n",
    "computerscience_template = \"\"\"你是一位成功的计算机科学家。\\\n",
    "你有创造力、懂协作、有前瞻性、有技术问题解决能力、你有对理论和算法的更以及出色的沟通技巧\\\n",
    "你充满热情。你擅长回答编码问题，\\\n",
    "因为你知道如何通过描述可由机器轻松解释的命令步骤来解决问题并提供一个在各方面较为平衡的方案。\n",
    "\n",
    "这是我的问题：\n",
    "{input}\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"适合回答物理问题\",\n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"适合回答数学问题\",\n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"history\",\n",
    "        \"description\": \"适合回答历史问题\",\n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\",\n",
    "        \"description\": \"适合回答计算机科学问题\",\n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "\n",
    "print(destination_chains)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] output_parser=RouterOutputParser() template='将原始文本输入到语言模型中，选择最适合该输入的提示词。你将获得最适合的提示名称以及相应的描述如果你认为修改原始输入会让语言模型有更好的响应结果，则可以进行修改。\\n\\n<< FORMATTING >>\\n返回一个 Markdown 代码片段，其中包含格式化为 JSON 对象的内容：\\n```json\\n{{\\n    \"destination\": string \\\\ 要使用的 prompt 名称，如果找不到则设置为 \"DEFAULT\"\\n    \"next_inputs\": string \\\\ 原始的输入，或者可能是原始输入的修改版本\\n}}\\n```\\n\\n记住：\"destination\" 必须是下面指定的候选提示名称之一，或者如果输入不适合任何候选提示，则可以是\"DEFAULT\"\\n记住：\"next_inputs\" 如果你认为不需要进行任何修改，可以直接使用原始输入。\\n\\n<< CANDIDATE PROMPTS >>\\nphysics: 适合回答物理问题\\nmath: 适合回答数学问题\\nhistory: 适合回答历史问题\\ncomputer science: 适合回答计算机科学问题\\n\\n<< INPUT >>\\n{input}\\n\\n<< OUTPUT (记住要包含 ```json)>>'\n"
     ]
    }
   ],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)\n",
    "\n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"将原始文本输入到语言模型中，\\\n",
    "选择最适合该输入的提示词。\\\n",
    "你将获得最适合的提示名称以及相应的描述\\\n",
    "如果你认为修改原始输入会让语言模型有更好的响应结果，则可以进行修改。\n",
    "\n",
    "<< FORMATTING >>\n",
    "返回一个 Markdown 代码片段，其中包含格式化为 JSON 对象的内容：\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ 要使用的 prompt 名称，如果找不到则设置为 \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ 原始的输入，或者可能是原始输入的修改版本\n",
    "}}}}\n",
    "```\n",
    "\n",
    "记住：\"destination\" 必须是下面指定的候选提示名称之一，或者如果输入不适合任何候选提示，则可以是\"DEFAULT\"\n",
    "记住：\"next_inputs\" 如果你认为不需要进行任何修改，可以直接使用原始输入。\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (记住要包含 ```json)>>\"\"\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import RouterOutputParser\n",
    "from langchain.chains import LLMRouterChain, MultiPromptChain\n",
    "\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt) # LLMRouterChain(llm=llm, prompt=router_prompt)\n",
    "\n",
    "print(router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: {'input': '为什么不在家？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'有很多可能的原因，可能是因为工作、学习、旅行、社交活动等。具体原因需要根据个人情况来确定。'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain,\n",
    "                         destination_chains=destination_chains,\n",
    "                         default_chain=default_chain,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history: {'input': '为什么秦始皇被称为嬴政？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'秦始皇被称为嬴政主要是因为这是他的尊号，也是他在位期间的称谓。\"嬴\"（yíng）是秦国的姓氏，\"政\"（zhèng）则是指皇帝的政治权力和统治地位。秦始皇在统一中国之后，采取了一系列的措施来巩固自己的权力和中央集权，使得他成为中国历史上第一个皇帝。他实行了一系列的改革和政策，包括统一文字、货币、度量衡等，修筑了万里长城和秦始皇陵等重大建筑工程，通过中央集权的措施加强了对地方的控制。因此，秦始皇在中国历史上的地位和贡献被认为是至关重要的，他被尊称为嬴政，也体现了他在政治和统治方面的卓越能力和成就。'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"为什么秦始皇是嬴政？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math: {'input': '2+2等于多少？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2+2等于4。'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"2+2等于多少？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\chains\\llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics: {'input': '什么是黑体辐射？'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'黑体辐射是指一个理想化的物体，它能够完全吸收并发射所有入射到它上面的电磁辐射，无论是可见光、红外线、紫外线还是其他频段的辐射。这个理想化的物体不会反射、折射或透过任何辐射，它能够以最高效率地吸收并重新辐射能量。\\n\\n黑体辐射是根据物体的温度来决定其辐射的特性。根据普朗克辐射定律，黑体辐射的强度与频率有关。随着温度的升高，黑体辐射的峰值频率也会升高，而辐射强度也会增加。\\n\\n黑体辐射在许多领域都有重要的应用，例如热力学、量子力学和宇宙学等。它对于理解能量传递、热辐射、光谱分析以及宇宙背景辐射等现象非常重要。'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"什么是黑体辐射？\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
